<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8" /> 
        <title> Artificial Intelligence 
        </title>
        <meta name="description" content="The role of artificial intelligence in all areas of life" />
    </head>
    <body>
        <h1>Artificial intelligence</h1>
        <P> is intelligence demonstrated by machines, unlike the <b>natural intelligence</b> displayed by humans and animals, which involves consciousness and emotionality. The distinction between the former and the latter categories is often revealed by the acronym chosen. 'Strong' AI is usually labelled as artificial general intelligence (AGI) while attempts to emulate 'natural' intelligence have been called artificial biological intelligence (ABI). Leading AI textbooks define the field as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of achieving its goals. Colloquially, the term "artificial intelligence" is often used to describe machines that mimic "cognitive" functions that humans associate with the human mind, such as "learning" and "problem solving".

            As machines become increasingly capable, tasks considered to require "intelligence" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says "AI is whatever hasn't been done yet. For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology. Modern machine capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems (such as chess and Go), and also imperfect-information games like poker, self-driving cars, intelligent routing in content delivery networks, and military simulations.
            
            Artificial intelligence was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an "AI winter"), followed by new approaches, success and renewed funding. After AlphaGo defeated a professional Go player in 2015, artificial intelligence once again attracted widespread global attention. For most of its history, AI research has been divided into sub-fields that often fail to communicate with each other. These sub-fields are based on technical considerations, such as particular goals (e.g. "robotics" or "machine learning"), the use of particular tools ("logic" or artificial neural networks), or deep philosophical differences. Sub-fields have also been based on social factors (particular institutions or the work of particular researchers).
            
            The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.AGI is among the field's long-term goals. Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields.
            
            The field was founded on the assumption that human intelligence "can be so precisely described that a machine can be made to simulate it". This raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction and philosophy since antiquity. Some people also consider AI to be a danger to humanity if it progresses unabated. Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.">
            
            In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.</P>
            <img src="https://mustafashokry.github.io/ece001/Images/AI1.jpg" alt=""width="600px">
            <h2>Machine learning</h2>
            <p> is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. And it is obvious that machine learning depends heavily on mathematics and statistics. As it applies a lot of mathematical and statical theories using programming languages such as python (and using a lot of its generous libraries)</p>
            <p><b>Machine learning</b> has three types depending on the data structure fitted to the model and whether it is labelled or not</p>
            <ol start="i">
                <li><b>Supervised learning</b> (structured data and labelled).
                </li>
                <li><b>unupervised learning</b> (structured data and unlabelled).
                </li>
                <li><b>Reinforcement learning</b> (real time data).
                </li>
            </ol>
            <img src="https://www.researchgate.net/profile/Livio-Pompianu/publication/303222728/figure/fig1/AS:423293980286978@1477932558682/A-diagram-of-the-middleware-architecture_Q640.jpg" alt="" width="600px">
            <p>As a simple example of structured labeled data, we can consider the following table which contains the prices of mobiles depending on some features:</p>
            <table border="1">      
                <thead>
                    <tr>
                        <th>sale price</th>
                        <th>year</th>
                        <th>mobile type
                        </th>
                    </tr>
                </thead>
                <body>
                    <tr>
                        <td>2000</td>
                        <td>2015</td>
                        <td>samsoung</td>
                    </tr>
                    <tr>
                        <td>4000</td>
                        <td>2017</td>
                        <td>samsoung</td>
                    </tr>
                    <tr>
                        <td>6000</td>
                        <td>2018</td>
                        <td>apple</td>
                    </tr>
                    <tr>
                        <td>10000</td>
                        <td>2020</td>
                        <td>apple</td>
                    </tr>
                </body>
            </table>
            <h3>History of artificial intelegens</h3>
            <p>began in antiquity, with myths, stories and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The seeds of modern AI were planted by classical philosophers who attempted to describe the process of human thinking as the mechanical manipulation of symbols. This work culminated in the invention of the programmable digital computer in the 1940s, a machine based on the abstract essence of mathematical reasoning. This device and the ideas behind it inspired a handful of scientists to begin seriously discussing the possibility of building an electronic brain.

                The field of AI research was founded at a workshop held on the campus of Dartmouth College during the summer of 1956.[1] Those who attended would become the leaders of AI research for decades. Many of them predicted that a machine as intelligent as a human being would exist in no more than a generation, and they were given millions of dollars to make this vision come true.
                
                Eventually, it became obvious that they had grossly underestimated the difficulty of the project. In 1973, in response to the criticism from James Lighthill and ongoing pressure from congress, the U.S. and British Governments stopped funding undirected research into artificial intelligence, and the difficult years that followed would later be known as an "AI winter". Seven years later, a visionary initiative by the Japanese Government inspired governments and industry to provide AI with billions of dollars, but by the late 80s the investors became disillusioned and withdrew funding again.
                
                Investment and interest in AI boomed in the first decades of the 21st century when machine learning was successfully applied to many problems in academia and industry due to new methods, the application of powerful computer hardware, and the collection of immense data sets.</p>
                <img src="https://data-flair.training/blogs/wp-content/uploads/sites/2/2019/09/History-of-Artificial-Intelligence-1200x720.jpg" alt="" width="600px">
                <h4>Reinforcement learning (RL)</h4>
                <p>is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward.[1] Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.

                    Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).[2]
                    
                    The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques.[3] The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.</p>
                    <img src="https://miro.medium.com/max/3216/1*9483SlfLtCh_jDkzFZyeYQ.jpeg" alt="" width="600px">
                    <p><b>Deep learning</b> (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.

                        Deep-learning architectures such as deep neural networks, deep belief networks, graph neural networks, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.
                        
                        Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.
                        
                        The adjective "deep" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the "structured" part.</p>
                        <img src="https://miro.medium.com/max/2646/1*Da7wVx5j1KcSJ-I4DVFZyQ.png" alt="" width="600px">
                        <p><b>APPLICATIONS OF Artificial intelligence</b>There are many applications of artificial intelligence, including those related to agriculture, education, health, education, health and electronic games
                        </p>
                        <img src="https://data-flair.training/blogs/wp-content/uploads/sites/2/2019/11/applications-of-AI-1.jpg" alt="600px">
            <ol start="i">
                <li><b>Agriculture</b></li>
                <p>In agriculture new AI advancements show improvements in gaining yield and to increase the research and development of growing crops. New artificial intelligence now predicts the time it takes for a crop like a tomato to be ripe and ready for picking thus increasing efficiency of farming.[3] These advances go on including Crop and Soil Monitoring, Agricultural Robots, and Predictive Analytics. Crop and soil monitoring uses new algorithms and data collected on the field to manage and track the health of crops making it easier and more sustainable for the farmers.[4]

                    More specializations of AI in agriculture is one such as greenhouse automation, simulation, modeling, and optimization techniques.
                    
                    Due to the increase in population and the growth of demand for food in the future, there will need to be at least a 70% increase in yield from agriculture to sustain this new demand. More and more of the public perceives that the adaption of these new techniques and the use of Artificial intelligence will help reach that goal.</p>
                    <img src="https://mytechpick.com/wp-content/uploads/2021/04/ai-in-farming-1-638.jpg" alt="600px">
                    <li><b>Education</b></li>
                    <p>AI tutors could allow for students to get extra, one-on-one help. They could also reduce anxiety and stress for some students, that may be caused by tutor labs or human tutors.[6] In future classrooms, ambient informatics can play a beneficial role. Ambient informatics is the idea that information is everywhere in the environment and that technologies automatically adjust to your personal preferences.[7] Study devices could be able to create lessons, problems, and games to tailor to the specific student's needs, and give immediate feedback.

                        But AI can also create a disadvantageous environment with revenge effects, if technology is inhibiting society from moving forward and causing negative, unintended effects on society.[8] An example of a revenge effect is that the extended use of technology may hinder studentsâ€™ ability to focus and stay on task instead of helping them learn and grow.[9] Also, AI has been known to lead to the loss of both human agency and simultaneity.</p>
                        <img src="https://www.jumpstartmag.com/wp-content/uploads/2021/02/Artificial-Intelligence-in-Education.jpeg" alt="600px">
                        <li><b>Finance</b></li>
                        <p>Financial institutions have long used artificial neural network systems to detect charges or claims outside of the norm, flagging these for human investigation. The use of AI in banking can be traced back to 1987 when Security Pacific National Bank in the US set-up a Fraud Prevention Task force to counter the unauthorized use of debit cards.[10] Programs like Kasisto and Moneystream are using AI in financial services.

                            Banks use artificial intelligence systems today to organize operations, maintain book-keeping, invest in stocks, and manage properties. AI can react to changes overnight or when business is not taking place.[11] In August 2001, robots beat humans in a simulated financial trading competition.[12] AI has also reduced fraud and financial crimes by monitoring behavioral patterns of users for any abnormal changes or anomalies.[13][14][15]
                            
                            AI is increasingly being used by corporations. Jack Ma has controversially predicted that AI CEO's are 30 years away.[16][17]
                            
                            The use of AI machines in the market in applications such as online trading and decision making has changed major economic theories.[18] For example, AI-based buying and selling platforms have changed the law of supply and demand in that it is now possible to easily estimate individualized demand and supply curves and thus individualized pricing. Furthermore, AI machines reduce information asymmetry in the market and thus making markets more efficient while reducing the volume of trades[citation needed]. Furthermore, AI in the markets limits the consequences of behavior in the markets again making markets more efficient.[19] Other theories where AI has had impact include in rational choice, rational expectations, game theory, Lewis turning point, portfolio optimization and counterfactual thinking.[20] In August 2019, the AICPA introduced an AI training course for accounting professionals</p>
                            <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZfFSKHRfperU_cHHrKB6eHtCw0p6jQulT35LaTODgomw1mc7gcOvfctRsfzop5V8T2NU&usqp=CAU" alt="700px">
                            <li><b>Government</b></li>
                            <p>Artificial intelligence in government consists of applications and regulation. Artificial intelligence paired with facial recognition systems may be used for mass surveillance. This is already the case in some parts of China.[32][33] Artificial intelligence has also competed in the Tama City mayoral elections in 2018.

                                In 2019, the tech city of Bengaluru in India is set to deploy AI managed traffic signal systems across the 387 traffic signals in the city. This system will involve use of cameras to ascertain traffic density and accordingly calculate the time needed to clear the traffic volume which will determine the signal duration for vehicular traffic across streets.</p>
                                <img src="https://internetofbusiness.com/wp-content/uploads/2018/07/AI-inforgraphic-1-750x350-300x140.png" alt="200px">
            </ol>  
        <p><b>My Sources</b></p>   
        <ol start="i">
            <li><a href="https://en.wikipedia.org/wiki/Artificial_intelligence" target="_blank">Artificial intelligence - Wikipedia</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Machine_learning" target="blank">Machine learning - Wikipedia</a></li>
            <li><a href="https://en.wikipedia.org/wiki/History_of_artificial_intelligence" target="_blank">History of artificial intelligence - Wikipedia</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">Reinforcement learning - Wikipedia</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep learning - Wikipedia</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence" target="_blank">Applications of artificial intelligence - Wikipedia</a></li>
            
        </ol>               
     </body>
</html>